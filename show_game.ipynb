{"cells":[{"cell_type":"code","execution_count":24,"metadata":{},"outputs":[],"source":["from stable_baselines3.common.vec_env.vec_frame_stack import VecFrameStack\n","from stable_baselines3.common.env_util import make_atari_env\n","from stable_baselines3.common.vec_env import VecVideoRecorder\n","import tensorflow as tf\n","\n","import time\n","import numpy as np\n","from IPython import display as ipythondisplay\n","from pyvirtualdisplay import Display\n","from PIL import Image\n","import random"]},{"cell_type":"code","execution_count":25,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Creating environment with 1 processes\n"]}],"source":["n_env = 1\n","print(\"Creating environment with {} processes\".format(n_env))\n","model_type = \"vanilla\"\n","model_detail = \"\"\n","model_path = f\"./{model_type}_DQN/model{model_detail}\"\n","video_path = f\"./{model_type}_DQN/video{model_detail}\"\n","\n","# Create the environment with 4 stacked frames\n","env = make_atari_env(\"ALE/MsPacman-v5\")\n","env = VecFrameStack(env, n_stack=4)\n","env = VecVideoRecorder(env, video_folder = video_path, record_video_trigger=lambda x: x == 0, video_length=1000, name_prefix=\"dqn-agent\")\n","\n","n_actions = env.action_space.n"]},{"cell_type":"code","execution_count":26,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n"]},{"name":"stderr","output_type":"stream","text":["WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n"]}],"source":["# load model\n","model = tf.keras.models.load_model(model_path)\n","eps = 0.1"]},{"cell_type":"code","execution_count":31,"metadata":{},"outputs":[],"source":["def predict(model, obs):\n","    if eps >= random.random():\n","        action = random.randint(0, n_actions - 1)\n","    else:\n","        # We can also use numpy but this is more efficient\n","        tensor_state = tf.convert_to_tensor(obs)\n","\n","        actions = model(tensor_state, training=False)[0]\n","        \n","        action = tf.argmax(actions).numpy()\n","    \n","    return [action]\n"]},{"cell_type":"code","execution_count":32,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Moviepy - Building video /home/mister/Desktop/PacmanDQN/vanilla_DQN/video/dqn-agent-step-0-to-step-1000.mp4.\n","Moviepy - Writing video /home/mister/Desktop/PacmanDQN/vanilla_DQN/video/dqn-agent-step-0-to-step-1000.mp4\n","\n"]},{"name":"stderr","output_type":"stream","text":["                                                                "]},{"name":"stdout","output_type":"stream","text":["Moviepy - Done !\n","Moviepy - video ready /home/mister/Desktop/PacmanDQN/vanilla_DQN/video/dqn-agent-step-0-to-step-1000.mp4\n"]},{"name":"stderr","output_type":"stream","text":["\r"]}],"source":["# Create a virtual display\n","display = Display(visible=0, size=(1200, 1200))\n","display.start()\n","\n","data = {i: [[]] for i in range(n_env)}\n","tmp_data = {i: 1 for i in range(n_env)}\n","\n","obs = env.reset()\n","\n","while True:\n","    actions = predict(model, obs)\n","    obs, rewards, dones, info = env.step(actions)\n","    \n","    for i in range(n_env):\n","        if tmp_data[i]-1 >= len(data[i]):\n","            data[i].append([])\n","        if rewards[i] is not None:  # Check if the reward is not None\n","            data[i][tmp_data[i]-1].append(rewards[i])\n","        if dones[i]:\n","            tmp_data[i] += 1\n","\n","    # Render the environment and display the frame\n","    screen = env.render()\n","    # Convert the RGB array to an image\n","    screen = Image.fromarray(screen)\n","\n","    ipythondisplay.clear_output(wait=True)\n","    ipythondisplay.display(screen)\n","    \n","    time.sleep(1/2)  # Delay for 1/30 seconds to achieve ~30 fps\n","\n","    if all([tmp_data[i] > 3 for i in range(n_env)]):\n","        break\n","\n","ipythondisplay.clear_output(wait=True)\n","env.close()"]},{"cell_type":"code","execution_count":54,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["{0: [[72.0, 109], [9.0, 37], [21.0, 103]]}\n"]}],"source":["import copy\n","from pprint import pprint\n","\n","copy_data = copy.deepcopy(data)\n","\n","for i in range(n_env):\n","    for j in range(len(copy_data[i])):\n","        copy_data[i][j] = [np.sum(copy_data[i][j]), len(copy_data[i][j])]\n","\n","pprint(copy_data)"]},{"cell_type":"code","execution_count":55,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Total episodes for CPU 0 : 2\n","Total reward for CPU 0 : 102.0 with average reward 34.00\n","Total steps for CPU 0 : 249 with average steps 83.00\n","Weighted average reward for CPU 0 : 41.54\n","\n","Total episodes: 3\n"]}],"source":["for i in range(n_env):\n","    print(\"Total episodes for CPU\", i, \":\", len(copy_data[i]))\n","    print(\"Total reward for CPU\", i, \":\", sum([copy_data[i][j][0] for j in range(len(copy_data[i]))]), \"with average reward\", format(sum([copy_data[i][j][0] for j in range(len(copy_data[i]))])/len(copy_data[i]), '.2f'))\n","    print(\"Total steps for CPU\", i, \":\", sum([copy_data[i][j][1] for j in range(len(copy_data[i]))]), \"with average steps\", format(sum([copy_data[i][j][1] for j in range(len(copy_data[i]))])/len(copy_data[i]), '.2f'))\n","    print(\"Weighted average reward for CPU\", i, \":\", format(sum([copy_data[i][j][0]*copy_data[i][j][1] for j in range(len(copy_data[i]))])/sum([copy_data[i][j][1] for j in range(len(copy_data[i]))]), '.2f'))\n","    print()\n","\n","print(\"Total episodes:\", sum([len(copy_data[i]) for i in range(n_env)]))"]}],"metadata":{"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":30636,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.5"}},"nbformat":4,"nbformat_minor":4}
