{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"execution":{"iopub.execute_input":"2024-01-11T11:22:19.182142Z","iopub.status.busy":"2024-01-11T11:22:19.181753Z","iopub.status.idle":"2024-01-11T11:22:19.187942Z","shell.execute_reply":"2024-01-11T11:22:19.186975Z","shell.execute_reply.started":"2024-01-11T11:22:19.182115Z"},"trusted":true},"outputs":[],"source":["class LinearIterator:\n","    def __init__(self, start, end, steps):\n","        self.start = start\n","        self.end = end\n","        self.steps = steps\n","    \n","    def value(self, step):\n","        return max(self.start + (self.end - self.start) * step / self.steps, self.end)"]},{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2024-01-11T11:22:19.189944Z","iopub.status.busy":"2024-01-11T11:22:19.189493Z","iopub.status.idle":"2024-01-11T11:22:38.587192Z","shell.execute_reply":"2024-01-11T11:22:38.586087Z","shell.execute_reply.started":"2024-01-11T11:22:19.189916Z"},"trusted":true},"outputs":[],"source":["#!pip install gymnasium[atari]\n","#!pip install gymnasium[accept-rom-license]"]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2024-01-11T11:22:38.588761Z","iopub.status.busy":"2024-01-11T11:22:38.588473Z","iopub.status.idle":"2024-01-11T11:22:48.255907Z","shell.execute_reply":"2024-01-11T11:22:48.255012Z","shell.execute_reply.started":"2024-01-11T11:22:38.588736Z"},"trusted":true},"outputs":[],"source":["#!pip install \"gym[accept-rom-license, atari]\""]},{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2024-01-11T11:22:48.257936Z","iopub.status.busy":"2024-01-11T11:22:48.257603Z","iopub.status.idle":"2024-01-11T11:22:48.263850Z","shell.execute_reply":"2024-01-11T11:22:48.262747Z","shell.execute_reply.started":"2024-01-11T11:22:48.257907Z"},"trusted":true},"outputs":[],"source":["import os, psutil  \n","\n","def cpu_stats():\n","    pid = os.getpid()\n","    py = psutil.Process(pid)\n","    memory_use = py.memory_info()[0] / 2. ** 30\n","    return 'memory GB:' + str(np.round(memory_use, 2))"]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2024-01-11T11:22:48.265318Z","iopub.status.busy":"2024-01-11T11:22:48.265070Z","iopub.status.idle":"2024-01-11T11:22:48.279144Z","shell.execute_reply":"2024-01-11T11:22:48.278410Z","shell.execute_reply.started":"2024-01-11T11:22:48.265296Z"},"trusted":true},"outputs":[],"source":["def get_train_fn():\n","    @tf.function\n","    def train_function(batch_state, action_mask, target, Q, loss_function, optimizer):\n","        with tf.GradientTape() as tape:\n","            q_pred = Q(batch_state)\n","            q_action = tf.reduce_sum(tf.multiply(q_pred, action_mask), axis=1)\n","            loss = loss_function(target, q_action)\n","\n","        grads = tape.gradient(loss, Q.trainable_variables)\n","        optimizer.apply_gradients(zip(grads, Q.trainable_variables))\n","        return loss\n","\n","    return train_function"]},{"cell_type":"code","execution_count":9,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2024-01-11T11:22:48.280838Z","iopub.status.busy":"2024-01-11T11:22:48.280524Z","iopub.status.idle":"2024-01-11T11:30:16.880857Z","shell.execute_reply":"2024-01-11T11:30:16.879634Z","shell.execute_reply.started":"2024-01-11T11:22:48.280798Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Initializing from scratch.\n","GPU is not available, using CPU instead\n","Creating checkpoint at step: 6000\n","Updating Q_target at episode: 6000\n","Experience replay size: 1\n","Running reward for episode: 0\n","Epsilon: 0.1\n","CPU stats: memory GB:1.69\n","Episode reward: 6.0\n","Episode reward: 0.0\n","Episode reward: 0.0\n","Episode reward: 13.0\n","Episode reward: 0.0\n","Episode reward: 8.0\n","Episode reward: 6.0\n","Episode reward: 0.0\n","Episode reward: 16.0\n","Episode reward: 6.0\n","Creating checkpoint at step: 6010\n","Episode reward: 14.0\n","Episode reward: 0.0\n","Episode reward: 6.0\n","Episode reward: 0.0\n","Episode reward: 0.0\n","Episode reward: 12.0\n","Episode reward: 3.0\n","Episode reward: 4.0\n","Episode reward: 6.0\n"]},{"ename":"KeyboardInterrupt","evalue":"","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","Cell \u001b[0;32mIn[9], line 131\u001b[0m\n\u001b[1;32m    129\u001b[0m     \u001b[38;5;66;03m# set last value to -1 if we have terminated. The goal is to avoid getting killed\u001b[39;00m\n\u001b[1;32m    130\u001b[0m     target \u001b[38;5;241m=\u001b[39m target \u001b[38;5;241m*\u001b[39m (\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m-\u001b[39m batch_done) \u001b[38;5;241m-\u001b[39m batch_done\n\u001b[0;32m--> 131\u001b[0m     \u001b[43mtrain_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch_state\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maction_mask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mQ\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss_function\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    133\u001b[0m obs \u001b[38;5;241m=\u001b[39m next_obs\n\u001b[1;32m    135\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(experience_replay) \u001b[38;5;241m>\u001b[39m max_replay_size:\n","File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n","File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:832\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    829\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    831\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 832\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    834\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    835\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n","File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:868\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    865\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m    866\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[1;32m    867\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[0;32m--> 868\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtracing_compilation\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    869\u001b[0m \u001b[43m      \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_no_variable_creation_config\u001b[49m\n\u001b[1;32m    870\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    871\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variable_creation_config \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    872\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[1;32m    873\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[1;32m    874\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n","File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py:139\u001b[0m, in \u001b[0;36mcall_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    137\u001b[0m bound_args \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mbind(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    138\u001b[0m flat_inputs \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39munpack_inputs(bound_args)\n\u001b[0;32m--> 139\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[1;32m    140\u001b[0m \u001b[43m    \u001b[49m\u001b[43mflat_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\n\u001b[1;32m    141\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py:1323\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[1;32m   1319\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1320\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1321\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1322\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1323\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_preflattened\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1324\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1325\u001b[0m     args,\n\u001b[1;32m   1326\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1327\u001b[0m     executing_eagerly)\n\u001b[1;32m   1328\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n","File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:216\u001b[0m, in \u001b[0;36mAtomicFunction.call_preflattened\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcall_preflattened\u001b[39m(\u001b[38;5;28mself\u001b[39m, args: Sequence[core\u001b[38;5;241m.\u001b[39mTensor]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[1;32m    215\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 216\u001b[0m   flat_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    217\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mpack_output(flat_outputs)\n","File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:251\u001b[0m, in \u001b[0;36mAtomicFunction.call_flat\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    249\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m record\u001b[38;5;241m.\u001b[39mstop_recording():\n\u001b[1;32m    250\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[0;32m--> 251\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_bound_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    252\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    253\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    254\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction_type\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflat_outputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    255\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    256\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    257\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m make_call_op_in_graph(\n\u001b[1;32m    258\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    259\u001b[0m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[1;32m    260\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mfunction_call_options\u001b[38;5;241m.\u001b[39mas_attrs(),\n\u001b[1;32m    261\u001b[0m     )\n","File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/tensorflow/python/eager/context.py:1486\u001b[0m, in \u001b[0;36mContext.call_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1484\u001b[0m cancellation_context \u001b[38;5;241m=\u001b[39m cancellation\u001b[38;5;241m.\u001b[39mcontext()\n\u001b[1;32m   1485\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1486\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1487\u001b[0m \u001b[43m      \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1488\u001b[0m \u001b[43m      \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1489\u001b[0m \u001b[43m      \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtensor_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1490\u001b[0m \u001b[43m      \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1491\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1492\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1493\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1494\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m   1495\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m   1496\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1500\u001b[0m       cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_context,\n\u001b[1;32m   1501\u001b[0m   )\n","File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/tensorflow/python/eager/execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     54\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"source":["import gymnasium as gym\n","import numpy as np\n","import tensorflow as tf\n","from tensorflow import keras\n","from keras.layers import Conv2D, Flatten, Dense\n","from stable_baselines3.common.vec_env.vec_frame_stack import VecFrameStack\n","from stable_baselines3.common.env_util import make_atari_env\n","from keras.models import Sequential\n","import random\n","import os\n","import gc \n","\n","gamma = 0.99\n","num_actions = 5\n","\n","initial_sample_size = 1000\n","batch_size = 32\n","max_episode_rew_history = 100\n","max_replay_size = 10000\n","target_update_period = 100\n","\n","experience_replay = []\n","episode_rew_history = []\n","episode_count = 6000\n","episode_rew = 0\n","training_episodes = 10000\n","running_reward = 0\n","q_updated = False\n","q_checkpoint = False\n","\n","# make_atari_env creates an environment which reduces image sizes\n","# clips rewards in the range of -1, 0, 1 and replaces RGB with grayscale\n","# VecFrameStack does 4 steps and stackes them on each other so we \n","# can better train seeing how the Pacman moves and how the ghosts move\n","env = VecFrameStack(make_atari_env(\"ALE/MsPacman-v5\"), n_stack=4)\n","\n","# Creates a simple convolutional NN to work with the images\n","def create_q_nn(num_actions):\n","    model = Sequential([\n","        Conv2D(32, 8, strides=4, activation=\"relu\", input_shape=(84, 84, 4)),\n","        Conv2D(64, 4, strides=2, activation=\"relu\"),\n","        Conv2D(64, 3, strides=1, activation=\"relu\"),\n","        Flatten(),\n","        Dense(512, activation=\"relu\"),\n","        Dense(num_actions, activation=\"linear\")\n","    ])\n","\n","    return model\n","\n","# target fixed network\n","Q_target = create_q_nn(num_actions)\n","# network we train\n","Q = create_q_nn(num_actions)\n","\n","eps_it = LinearIterator(1, 0.1, training_episodes/100 * 35)\n","obs = env.reset().squeeze()\n","\n","\n","train_fn = get_train_fn()\n","optimizer = tf.keras.optimizers.Adam(learning_rate=0.00030, clipnorm=1.0)\n","loss_function = keras.losses.Huber()\n","\n","checkpoint_dir = './checkpoints'\n","\n","# Create the directory if it doesn't exist\n","if not os.path.exists(checkpoint_dir):\n","    os.makedirs(checkpoint_dir)\n","\n","checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")\n","checkpoint = tf.train.Checkpoint(optimizer=optimizer, model=Q)\n","checkpoint_interval = 10\n","\n","# Restore the latest checkpoint if it exists\n","if tf.train.latest_checkpoint(\"/kaggle/input/checkpoints/checkpoints\"):\n","    checkpoint.restore(tf.train.latest_checkpoint(\"/kaggle/input/checkpoints/checkpoints\"))\n","    print(\"Restored from {}\".format(tf.train.latest_checkpoint(checkpoint_dir)))\n","    Q_target.set_weights(Q.get_weights())\n","else:\n","    print(\"Initializing from scratch.\")\n","\n","if tf.config.list_physical_devices('GPU'):\n","    print(\"GPU is available\")\n","    device = '/GPU:0'\n","else:\n","    print(\"GPU is not available, using CPU instead\")\n","    device = '/CPU:0'\n","\n","with tf.device(device):\n","    # Maybe change to MSE\n","    while training_episodes >= episode_count:\n","        eps = eps_it.value(episode_count)\n","        if eps >= random.random():\n","            action = random.randint(0, 4)\n","        else:\n","            # We can also use numpy but this is more efficient\n","            tensor_state = tf.convert_to_tensor(obs)\n","            # Dimensions need to be expanded cause the model expects a batch/not a single element\n","            expanded_state = tf.expand_dims(tensor_state, axis=0)\n","            actions = Q(expanded_state, training=False)[0]\n","            action = tf.argmax(actions).numpy()\n","\n","        # Made to work with only one environment because I want to use StackedFrames\n","        # and it doesn't work with non vectorized environments\n","        next_obs, rew, done, info = env.step([action])\n","        rew = rew[0]\n","        done = done[0]\n","        info = info[0]\n","        next_obs = next_obs.squeeze()\n","\n","        experience_replay.append((obs, action, rew, next_obs, done))\n","\n","        episode_rew += rew\n","\n","        if initial_sample_size < len(experience_replay):\n","            batch_idx = random.sample(range(0, len(experience_replay) - 1), batch_size)\n","\n","            batch_state = np.array([experience_replay[idx][0] for idx in batch_idx])\n","            batch_action = [experience_replay[idx][1] for idx in batch_idx]\n","            batch_rew = [experience_replay[idx][2] for idx in batch_idx]\n","            batch_next_state = np.array([experience_replay[idx][3] for idx in batch_idx])\n","            batch_done = tf.convert_to_tensor([float(experience_replay[idx][4]) for idx in batch_idx])\n","\n","            # one hot encoded actions\n","            action_mask = tf.one_hot(batch_action, num_actions)\n","            target_val = Q_target.predict(batch_next_state, verbose=0)\n","\n","            target = batch_rew + gamma * tf.reduce_max(target_val, axis=1)\n","\n","            # set last value to -1 if we have terminated. The goal is to avoid getting killed\n","            target = target * (1 - batch_done) - batch_done\n","            train_fn(batch_state, action_mask, target, Q, loss_function, optimizer)\n","\n","        obs = next_obs\n","        \n","        if len(experience_replay) > max_replay_size:\n","            del experience_replay[:1] \n","        \n","        if len(episode_rew_history) > max_episode_rew_history:\n","            del episode_rew_history[:1]\n","        \n","        if done:\n","            print(\"Episode reward: {}\".format(episode_rew))\n","            episode_rew_history.append(episode_rew)\n","            obs = env.reset().squeeze()\n","            episode_rew = 0\n","            episode_count += 1\n","            q_updated = False\n","            q_checkpoint = False\n","\n","        if len(episode_rew_history) > 0:\n","            running_reward = np.mean(episode_rew_history) \n","            \n","        #if running_reward > 20 and episode_count >= 90:\n","        #    print(running_reward)\n","        #   Q.save(\"./Q_model\")\n","        #    break\n","    \n","        if episode_count % checkpoint_interval == 0 and episode_count != 0 and not q_checkpoint:\n","            q_checkpoint = True\n","            print(\"Creating checkpoint at step: {}\".format(episode_count))\n","            checkpoint.save(file_prefix = checkpoint_prefix)\n","            tf.keras.backend.clear_session()\n","            checkpoint.restore(tf.train.latest_checkpoint(checkpoint_dir))\n","            Q_target.set_weights(Q.get_weights())\n","            \n","        if episode_count != 0 and episode_count % target_update_period == 0 and not q_updated:\n","            gc.collect()\n","            print(\"Updating Q_target at episode: {}\".format(episode_count))\n","            print(\"Experience replay size: {}\".format(len(experience_replay)))\n","            print(\"Running reward for episode: {}\".format(running_reward))\n","            print(\"Epsilon: {}\".format(eps))\n","            print(\"CPU stats: {}\".format(cpu_stats()))\n","            with open('running_rewards.txt', 'a') as f:\n","                f.write(\"Running reward at episode: {} {}\\n\".format(running_reward, episode_count))\n","            Q_target.set_weights(Q.get_weights())\n","            q_updated = True\n","\n","\n","print(\"Final running reward: {}\".format(running_reward))\n","with open('running_rewards.txt', 'a') as f:\n","    f.write(\"Running reward at episode: {} last\\n\".format(running_reward))\n","\n","Q.save(\"./Q_model\")\n","env.close()\n","print(\"Training finished!\")"]}],"metadata":{"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":30627,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.5"}},"nbformat":4,"nbformat_minor":4}
